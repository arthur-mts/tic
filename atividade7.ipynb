{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Atividade 7",
   "id": "be16655007779e98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A tarefa consiste em rodar e explicar a implementação do tutorial Entropy and Perplexity on Image and Text .pdf, usando como base para o conceito de perplexidade as discussões em aula e o texto Perplexity.pdf.",
   "id": "fd27d5d988301b2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Código e explicação",
   "id": "51db5820c5d63f22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cálculo de Entropia em Texto:\n",
    "\n",
    "- O texto é limpo (removendo pontuação) e dividido em palavras.\n",
    "- A frequência de cada palavra é calculada.\n",
    "- A entropia é computada com base na distribuição de probabilidade das palavras, usando a fórmula:"
   ],
   "id": "2e2055efafc807b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$H = -Σ p(i) log2 p(i)$$  \n",
    " onde p(i) é a probabilidade da palavra i."
   ],
   "id": "99b4e97c868ad845"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- As palavras são ordenadas pela sua \"autoinformação\" ($-log2 p(i)$), que indica o conteúdo informativo de cada palavra. Palavras raras têm maior autoinformação.",
   "id": "9ffe1741d1fc8085"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cálculo de Entropia em Imagens:\n",
    "\n",
    "- Uma imagem em tons de cinza é carregada.\n",
    "- A função get_entropy_of_image calcula a entropia em janelas deslizantes na imagem. Para cada pixel, a entropia é calculada em uma vizinhança definida.\n",
    "- A entropia é visualizada em um mapa de cores, onde áreas de alta variância (bordas, texturas) apresentam maior entropia."
   ],
   "id": "ef9b9df3c5dff0a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cálculo de Perplexidade em Imagens:\n",
    "\n",
    "Perplexidade é uma medida de quão bem um modelo de probabilidade prevê uma amostra. No contexto específico do Processamento de Linguagem Natural (PLN), a perplexidade serve para avaliar a performance de modelos de linguagem. Em essência, ela mede o quão \"surpreso\" ou \"perplexo\" o modelo fica diante de um texto que ele deve prever.\n",
    "\n",
    "- A função get_perplexity_of_image calcula a perplexidade da mesma forma que a entropia, mas usando a fórmula:\n",
    "    $$Perplexidade = 2 ^ {Entropia}$$\n",
    "- A perplexidade também é visualizada, realçando ainda mais as bordas e texturas."
   ],
   "id": "2d7ab097c6a73242"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conexão com o Conceito de Perplexidade\n",
    "- Modelos de Linguagem: No contexto de PLN, a perplexidade mede quão bem um modelo de linguagem prevê um texto. Um modelo que atribui altas probabilidades a sequências de palavras comuns terá baixa perplexidade.\n",
    "- Entropia: A perplexidade está diretamente relacionada à entropia. Baixa entropia indica alta previsibilidade (e, portanto, baixa perplexidade), enquanto alta entropia indica alta imprevisibilidade (e alta perplexidade).\n",
    "- Interpretação: No tutorial, a perplexidade em imagens realça bordas e texturas. Isso ocorre porque essas regiões têm alta variância e, portanto, são menos previsíveis, resultando em maior perplexidade."
   ],
   "id": "7eb36220e4929808"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21c04989605ac49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
